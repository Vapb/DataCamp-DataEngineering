{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_arguments = {\n",
    "    'owner': 'jdoe',\n",
    "    'email': 'jdoe@datacamp.com',\n",
    "    'start_date': datetime(2020,1,20) # Represents the earliest date that a DAG could run\n",
    "}\n",
    "\n",
    "etl_dag = DAG(\n",
    "    dag_id='etl_workflow',\n",
    "    default_args=default_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BashOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.bash_operator import BashOperator\n",
    "\n",
    "example_task = BashOperator(\n",
    "    task_id='bash_example',\n",
    "    bash_operator='echo \"Example\"',\n",
    "    dag=ml_dag # The dag it belogns to\n",
    ")\n",
    "\n",
    "bash_task = BashOperator(\n",
    "    task_id= 'clean_addresses',\n",
    "    bash_operator='cat addresses.tx | awk \"NF==10\" > cleaned.txt',\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "BashOperator(\n",
    "    task_id='bash_script_example',\n",
    "    bash_operator='runcleanup.sh',\n",
    "    dag=ml_dag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = BashOperator(\n",
    "    task_id='first_task',\n",
    "    bash_command='echo 1',\n",
    "    dag=example_dag\n",
    ")\n",
    "\n",
    "task2 = BashOperator(\n",
    "    task_id='second_task',\n",
    "    bash_command='echo 2',\n",
    "    dag=example_dag\n",
    ")\n",
    "\n",
    "# Set first_task to run before second_task\n",
    "task1 >> task2 # or task2 << task1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PythonOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "def printme():\n",
    "    print('this goes in the logs!')\n",
    "\n",
    "python_task = PythonOperator(\n",
    "    task_id='simple_print',\n",
    "    python_callable=printme,\n",
    "    dag=example_dag\n",
    ")\n",
    "\n",
    "def sleep(length_of_time):\n",
    "    time.sleep(length_of_time)\n",
    "\n",
    "sleep_task = PythonOperator(\n",
    "    task_id='sleep',\n",
    "    python_callable=sleep,\n",
    "    op_kwargs={'length_of_time':5}\n",
    "    dag=example_dag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmailOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.email_operator import EmailOperator\n",
    "\n",
    "email_task = EmailOperator(\n",
    "    task_id='email_sales_report',\n",
    "    to='sales_manager@example.com',\n",
    "    subject='Automated Sales Rport',\n",
    "    html_content='Attached is the latest sales report',\n",
    "    files='latest_sales.xlsx',\n",
    "    dag=example_dag\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FileSensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from airflow.sensors.base_sensor_operator import \n",
    "\n",
    "from airflow.contrib.sensors.file_sensor import FileSensor\n",
    "\n",
    "file_sensor_task = FileSensor(\n",
    "    taskid='file_sense',\n",
    "    filepath='salesdata.csv',\n",
    "    poke_interval=300, # 300 second = 5 mins\n",
    "    dag=sales_report_dag\n",
    ")\n",
    "\n",
    "init_sales_cleanup >> file_sensor_task >> generate_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BashOperator(\n",
    "    task_id='sla_task',\n",
    "    bash_command='runcode.sh',\n",
    "    sla=timedelta(seconds=30),\n",
    "    dag=dag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the timedelta object\n",
    "from datetime import timedelta\n",
    "\n",
    "# Create the dictionary entry\n",
    "default_args = {\n",
    "  'start_date': datetime(2020, 2, 20),\n",
    "  'sla': timedelta(minutes=30)\n",
    "}\n",
    "\n",
    "# Add to the DAG\n",
    "test_dag = DAG('test_workflow', default_args=default_args, schedule_interval='@None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args ={\n",
    "    'email':['airflowalers@datacamp.com'],\n",
    "    'email_on_failure':True,\n",
    "    'email_on_retry':False,\n",
    "    'email_on_sucess':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.contrib.sensors.file_sensor import FileSensor\n",
    "from datetime import datetime\n",
    "\n",
    "default_args={\n",
    "    'email': ['airflowalerts@datacamp.com','airflowadmin@datacamp.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_success':True\n",
    "}\n",
    "report_dag = DAG(\n",
    "    dag_id = 'execute_report',\n",
    "    schedule_interval = \"0 0 * * *\",\n",
    "    default_args=default_args\n",
    ")\n",
    "\n",
    "precheck = FileSensor(\n",
    "    task_id='check_for_datafile',\n",
    "    filepath='salesdata_ready.csv',\n",
    "    start_date=datetime(2020,2,20),\n",
    "    mode='reschedule',\n",
    "    dag=report_dag)\n",
    "\n",
    "generate_report_task = BashOperator(\n",
    "    task_id='generate_report',\n",
    "    bash_command='generate_report.sh',\n",
    "    start_date=datetime(2020,2,20),\n",
    "    dag=report_dag\n",
    ")\n",
    "\n",
    "precheck >> generate_report_task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templated_command=\"\"\"\n",
    "    echo \"Reading {{ params.filename }}\"\n",
    "\"\"\"\n",
    "\n",
    "t1 = BashOperator(\n",
    "    task_id='template_task',\n",
    "    bash_command=templated_command,\n",
    "    params={'filename': 'file1.txt'},\n",
    "    dag=example_dag\n",
    ")\n",
    "\n",
    "t2 = BashOperator(\n",
    "    task_id='template_task2',\n",
    "    bash_command=templated_command,\n",
    "    params={'filename': 'file2.txt'},\n",
    "    dag=example_dag\n",
    ")\n",
    "\n",
    "t1 >> t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jinja PL for more advanced templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templated_command = \"\"\"\n",
    "{% for filename in params.filenames %}\n",
    "    echo \"Reading {{ filename }}\"\n",
    "{% endfor %}\n",
    "\"\"\"\n",
    "\n",
    "t1 = BashOperator(\n",
    "    task_id='template_task',\n",
    "    bash_command=templated_command,\n",
    "    params={'filenames': ['file1.txt', 'fil2.txt']},\n",
    "    dag=example_dag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from datetime import datetime\n",
    "\n",
    "filelist = [f'file{x}.txt' for x in range(30)]\n",
    "\n",
    "default_args = {\n",
    "  'start_date': datetime(2020, 4, 15),\n",
    "}\n",
    "\n",
    "cleandata_dag = DAG('cleandata',\n",
    "                    default_args=default_args,\n",
    "                    schedule_interval='@daily')\n",
    "\n",
    "# Modify the template to handle multiple files in a \n",
    "# single run.\n",
    "templated_command = \"\"\"\n",
    "  <% for filename in params.filenames %>\n",
    "  bash cleandata.sh {{ ds_nodash }} {{ filename }};\n",
    "  <% endfor %>\n",
    "\"\"\"\n",
    "\n",
    "# Modify clean_task to use the templated command\n",
    "clean_task = BashOperator(task_id='cleandata_task',\n",
    "                          bash_command=templated_command,\n",
    "                          params={'filenames': filelist},\n",
    "                          dag=cleandata_dag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from airflow.operators.email_operator import EmailOperator\n",
    "from datetime import datetime\n",
    "\n",
    "# Create the string representing the html email content\n",
    "html_email_str = \"\"\"\n",
    "Date: {{ ds }}\n",
    "Username: {{ params.username }}\n",
    "\"\"\"\n",
    "\n",
    "email_dag = DAG('template_email_test',\n",
    "                default_args={'start_date': datetime(2020, 4, 15)},\n",
    "                schedule_interval='@weekly')\n",
    "                \n",
    "email_task = EmailOperator(task_id='email_task',\n",
    "                           to='testuser@datacamp.com',\n",
    "                           subject=\"{{ macros.uuid.uuid4() }}\",\n",
    "                           html_content=html_email_str,\n",
    "                           params={'username': 'testemailuser'},\n",
    "                           dag=email_dag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch_test(**kwargs):\n",
    "    if int(kwargs['ds_nodash']) % 2 == 0:\n",
    "        return 'even_day_task'\n",
    "    else:\n",
    "        return 'odd_day_task'\n",
    "\n",
    "branch_task = BranchPythonOperator(\n",
    "    task_id='branch_task',\n",
    "    provide_context=True,\n",
    "    python_callable=branch_test,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "start_task >> branch_task >> even_day_task >> even_day_task2\n",
    "branch_task >> odd_day_task >> odd_day_task2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a9c283881288bc8345488d89afcea2916cc52ed9130ad0e473a7427fa4f195f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
