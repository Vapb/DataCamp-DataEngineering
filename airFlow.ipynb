{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_arguments = {\n",
    "    'owner': 'jdoe',\n",
    "    'email': 'jdoe@datacamp.com',\n",
    "    'start_date': datetime(2020,1,20) # Represents the earliest date that a DAG could run\n",
    "}\n",
    "\n",
    "etl_dag = DAG(\n",
    "    dag_id='etl_workflow',\n",
    "    default_args=default_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BashOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.bash_operator import BashOperator\n",
    "\n",
    "example_task = BashOperator(\n",
    "    task_id='bash_example',\n",
    "    bash_operator='echo \"Example\"',\n",
    "    dag=ml_dag # The dag it belogns to\n",
    ")\n",
    "\n",
    "bash_task = BashOperator(\n",
    "    task_id= 'clean_addresses',\n",
    "    bash_operator='cat addresses.tx | awk \"NF==10\" > cleaned.txt',\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "BashOperator(\n",
    "    task_id='bash_script_example',\n",
    "    bash_operator='runcleanup.sh',\n",
    "    dag=ml_dag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = BashOperator(\n",
    "    task_id='first_task',\n",
    "    bash_command='echo 1',\n",
    "    dag=example_dag\n",
    ")\n",
    "\n",
    "task2 = BashOperator(\n",
    "    task_id='second_task',\n",
    "    bash_command='echo 2',\n",
    "    dag=example_dag\n",
    ")\n",
    "\n",
    "# Set first_task to run before second_task\n",
    "task1 >> task2 # or task2 << task1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PythonOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "def printme():\n",
    "    print('this goes in the logs!')\n",
    "\n",
    "python_task = PythonOperator(\n",
    "    task_id='simple_print',\n",
    "    python_callable=printme,\n",
    "    dag=example_dag\n",
    ")\n",
    "\n",
    "def sleep(length_of_time):\n",
    "    time.sleep(length_of_time)\n",
    "\n",
    "sleep_task = PythonOperator(\n",
    "    task_id='sleep',\n",
    "    python_callable=sleep,\n",
    "    op_kwargs={'length_of_time':5}\n",
    "    dag=example_dag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmailOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.email_operator import EmailOperator\n",
    "\n",
    "email_task = EmailOperator(\n",
    "    task_id='email_sales_report',\n",
    "    to='sales_manager@example.com',\n",
    "    subject='Automated Sales Rport',\n",
    "    html_content='Attached is the latest sales report',\n",
    "    files='latest_sales.xlsx',\n",
    "    dag=example_dag\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FileSensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from airflow.sensors.base_sensor_operator import \n",
    "\n",
    "from airflow.contrib.sensors.file_sensor import FileSensor\n",
    "\n",
    "file_sensor_task = FileSensor(\n",
    "    taskid='file_sense',\n",
    "    filepath='salesdata.csv',\n",
    "    poke_interval=300, # 300 second = 5 mins\n",
    "    dag=sales_report_dag\n",
    ")\n",
    "\n",
    "init_sales_cleanup >> file_sensor_task >> generate_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BashOperator(\n",
    "    task_id='sla_task',\n",
    "    bash_command='runcode.sh',\n",
    "    sla=timedelta(seconds=30),\n",
    "    dag=dag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the timedelta object\n",
    "from datetime import timedelta\n",
    "\n",
    "# Create the dictionary entry\n",
    "default_args = {\n",
    "  'start_date': datetime(2020, 2, 20),\n",
    "  'sla': timedelta(minutes=30)\n",
    "}\n",
    "\n",
    "# Add to the DAG\n",
    "test_dag = DAG('test_workflow', default_args=default_args, schedule_interval='@None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args ={\n",
    "    'email':['airflowalers@datacamp.com'],\n",
    "    'email_on_failure':True,\n",
    "    'email_on_retry':False,\n",
    "    'email_on_sucess':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.contrib.sensors.file_sensor import FileSensor\n",
    "from datetime import datetime\n",
    "\n",
    "default_args={\n",
    "    'email': ['airflowalerts@datacamp.com','airflowadmin@datacamp.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_success':True\n",
    "}\n",
    "report_dag = DAG(\n",
    "    dag_id = 'execute_report',\n",
    "    schedule_interval = \"0 0 * * *\",\n",
    "    default_args=default_args\n",
    ")\n",
    "\n",
    "precheck = FileSensor(\n",
    "    task_id='check_for_datafile',\n",
    "    filepath='salesdata_ready.csv',\n",
    "    start_date=datetime(2020,2,20),\n",
    "    mode='reschedule',\n",
    "    dag=report_dag)\n",
    "\n",
    "generate_report_task = BashOperator(\n",
    "    task_id='generate_report',\n",
    "    bash_command='generate_report.sh',\n",
    "    start_date=datetime(2020,2,20),\n",
    "    dag=report_dag\n",
    ")\n",
    "\n",
    "precheck >> generate_report_task\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a9c283881288bc8345488d89afcea2916cc52ed9130ad0e473a7427fa4f195f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
